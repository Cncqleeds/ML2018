{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据表示\n",
    "* 状态 state: 例如 state = np.zeros((3,3),dtype=np.float32)\n",
    "* 网络策略 p: 例如 p = np.array([0.1,0.2,0.05,0.1,0.4,0.15],dtype=np.float32)\n",
    "* MCTS策略 pi: 同p格式一致\n",
    "* 网络值 v: 为float型标量 例如 v = 0.75\n",
    "* 模拟器结果 z: 为float型标量 例如 v = -1.0\n",
    "* 动作 action: 为int型标量 例如 action = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 超参数\n",
    "\n",
    "* 问题规模 size: 例如 size = 19\n",
    "* 输入历史表示规模 history: 例如 history = 8\n",
    "* 每层卷积层核的个数 filters: 例如 filters = 256\n",
    "* 残差模块的个数 n_modules: n_modules = 19\n",
    "* 正则化参数 lambda_c: lambda_c = .0001\n",
    "* 动作空间的大小 n_actions: n_actions = 9\n",
    "* 探索与利用的平衡参数 c_puct: c_puct = 5\n",
    "* 探索与利用的惯性因子 epsilon: epsilon = .25\n",
    "* 探索与利用的Dirchlet分布参数 eta: eta = .03\n",
    "* 退火算法参数 tau: tau = .7\n",
    "* 搜索次数 n_search: n_search = 1600\n",
    "* 搜索最大深度 max_search_depth: max_search_depth = 20\n",
    "* 执行最大步数 max_play_steps: max_play_steps = 500\n",
    "* 估值阈值 v_resign: v_resign = -.95\n",
    "* 网络损失函数的迭代次数 n_iters: n_iters = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数学公式\n",
    "\n",
    "1. annealing(arr,tau) # 退火公式，arr为计数值\n",
    "2. sampling_from_dirchlet(alpha,size) # 从狄利克雷分布中采样,alpha为噪声参数，size为采样大小\n",
    "3. add_noise_to_p(p,epsilon,eta) # 为策略p加入噪声eta\n",
    "4. ucb(p,n_visits,c_puct) # 上置信界计算，p为策略，n_visits为访问数\n",
    "5. cross_entropy(p,q) # p与q的交叉熵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 内部函数及参数命名规范"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Net类\n",
    "\n",
    "1. p_op,v_op = inference(state)\n",
    "2. p = get_var_value(p_op,feed_dict) \n",
    "3. v = get_var_value(v_op,feed_dict)\n",
    "4. l_op = loss_op(z,v_op,pi,p_op,lambda_c) # 单个的状态的loss\n",
    "5. optimizer = minimize(l_op)\n",
    "6. l = get_var_value(l_op,feed_dict)\n",
    "7. update() # 将 T个state，T个pi，T个z ,迭代次数n_iters传入，更新网络参数\n",
    "8. 初始化state_placeholder, z_placeholder,pi_placeholder为placeholder类型\n",
    "9. save_params()\n",
    "10. restore_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TreeNode类\n",
    "1. action, sub_node = select()\n",
    "2. expand(action_priors)\n",
    "3. update(leaf_value,c_puct)\n",
    "4. backup(leaf_value,c_puct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MCTS类\n",
    "1. search() # 单次搜索\n",
    "2. pi = policy(state,tao) # 多次搜索后返回pi\n",
    "3. action = choice(tao) # 在当前state下给出action，是外界调用的接口\n",
    "4. next_prepare() # 为下次搜索做准备，在choice中调用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulator类\n",
    "1. move(action)\n",
    "2. get_state(state,action)\n",
    "3. render()\n",
    "4. is_done() # 判断是否结束\n",
    "5. who_win() # 1 代表赢， -1 代表输， 0 代表未结束 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. 初始化神经网络\n",
    "1. 模拟一局，进行自我对弈，每一步进行n_search次MCTS模拟，\n",
    "2. 一局结束后 将每一步的 s pi  z 及相应的旋转作为训练样本进行保存以供训练。\n",
    "3. 显示过程和结果并保存记录\n",
    "4. 训练网络，从最近的500万个样本中抽取2048个样本进行训练\n",
    "5. 更新网络，每1000局后，评估当前的神经网络和以前最佳的神经网络版本（两个版本进行对弈），如果胜率达到55%以上，则使用当前的神经网络作为最佳的版本，摒弃以前的版本\n",
    "6. 跳转 1. 循环 70万次\n",
    "7. 效果评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参考文献"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorflow中batch normalization的用法及其L2正则化 https://www.cnblogs.com/hrlnw/p/7227447.html\n",
    "\n",
    "AlphaGo Zero 原理 http://www.sohu.com/a/220095461_297710"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 超参数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = 3\n",
    "history = 1\n",
    "state_channal = 1 # 2 * history +1\n",
    "filters = 16\n",
    "n_modules = 7\n",
    "lambda_c = 0.0001\n",
    "n_actions = size*size\n",
    "c_puct = 2 \n",
    "epsilon = 0.25\n",
    "eta = 0.03\n",
    "init_tau = 1.0\n",
    "n_search = 1600\n",
    "max_search_depth = 10\n",
    "max_play_steps = 500\n",
    "v_resign = -0.95\n",
    "n_iters = 50\n",
    "\n",
    "dir_path = \"H:\\\\CnCqLeeds\\\\code\\\\致敬 AlphaGo Zero\\\\Model_save\"\n",
    "model_path = dir_path + \"\\\\model_net_demo.ckpt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数学公式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def annealing(arr,tau):\n",
    "    \"\"\"\n",
    "    退火公式，arr为计数值\n",
    "    \"\"\"\n",
    "    return np.power(arr,1.0/tau) / np.sum(np.power(arr,1.0/tau))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sampling_from_dirchlet(alpha,size):\n",
    "    \"\"\"\n",
    "    从狄利克雷分布中采样,alpha为噪声参数，size为采样大小\n",
    "    \"\"\"\n",
    "    eta = np.random.dirichlet([alpha]*size)\n",
    "    return eta,eta[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_noise_to_p(p,action,epsilon=.25,eta=0.03):\n",
    "    \"\"\"\n",
    "    为策略p加入噪声eta\n",
    "    \"\"\"\n",
    "    eta,_ = sampling_from_dirchlet(eta,p.size)\n",
    "    res = (1-epsilon) * p + epsilon * eta\n",
    "    return res,res[action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ucb(p,n_visits,action,c_puct):\n",
    "    \"\"\"\n",
    "    上置信界计算，p为策略，n_visits为访问数\n",
    "    \"\"\"\n",
    "    temp = c_puct * p * np.sqrt(np.sum(n_visits)) / (1+np.array(n_visits))\n",
    "    return temp, temp[action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_entropy(p,q): \n",
    "    \"\"\"\n",
    "    p与q的交叉熵\n",
    "    \"\"\"\n",
    "    return np.dot(np.array(p),np.log(np.array(q)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = np.array([0.1,0.5,0.05,.2,.15])\n",
    "q = np.array([.2,.3,.005,.095,.4])\n",
    "n_visits = [0,0,1,0,0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Net 类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Net:\n",
    "    def __init__(self):\n",
    "        self.state_ph = tf.placeholder(tf.float32,shape=(None,size,size,state_channal))\n",
    "        self.z_ph = tf.placeholder(tf.float32,shape=(None,1))\n",
    "        self.pi_ph = tf.placeholder(tf.float32,shape=(None,n_actions))\n",
    "        \n",
    "        self.training = True # 区分训练和测试\n",
    "        \n",
    "        self.p_op, self.v_op = self.inference(training=self.training)\n",
    "        \n",
    "        self.l_op = self.loss_op()\n",
    "        \n",
    "        self.optimizer = self.minimize(self.training)\n",
    "        \n",
    "        self.saver = self.get_saver()\n",
    "        \n",
    "        self.sess = tf.Session()\n",
    "        \n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    def set_training(self,training=True):\n",
    "        self.training = training\n",
    "\n",
    "    def get_training(self):\n",
    "        return self.training\n",
    "    \n",
    "    def get_saver(self):\n",
    "        var_list = tf.trainable_variables()\n",
    "#         print(\"1>>>\",len(var_list))\n",
    "        g_list = tf.global_variables()\n",
    "        bn_moving_vars = [g for g in g_list if 'moving_mean' in g.name]\n",
    "        bn_moving_vars += [g for g in g_list if 'moving_variance' in g.name]\n",
    "        var_list += bn_moving_vars\n",
    "#         print(\"2>>>\",len(var_list))\n",
    "        saver = tf.train.Saver(var_list=var_list, max_to_keep=5)\n",
    "        return saver\n",
    "        \n",
    "    def input_module(self,inputs,filters,training):\n",
    "        outputs = tf.layers.conv2d(inputs,filters=filters,kernel_size=3,padding='same')\n",
    "        outputs = tf.layers.batch_normalization(outputs,training=training)\n",
    "        outputs = tf.nn.relu(outputs)\n",
    "        return outputs\n",
    "\n",
    "    def residual_module(self,inputs,filters,training):\n",
    "        outputs = tf.layers.conv2d(inputs,filters=filters,kernel_size=3,padding='same')\n",
    "        outputs = tf.layers.batch_normalization(outputs,training=training)\n",
    "        outputs = tf.nn.relu(outputs)\n",
    "\n",
    "        outputs = tf.layers.conv2d(outputs,filters=filters,kernel_size=3,padding='same')\n",
    "        outputs = tf.layers.batch_normalization(outputs,training=training)\n",
    "\n",
    "        outputs += inputs\n",
    "        outputs = tf.nn.relu(outputs)  \n",
    "        return outputs\n",
    "    \n",
    "    def output_module(self,inputs,fc_units_v,training):\n",
    "        outputs_v = tf.layers.conv2d(inputs,filters=1,kernel_size=1,padding='same')\n",
    "        outputs_v = tf.layers.batch_normalization(outputs_v,training=training)\n",
    "        outputs_v = tf.nn.relu(outputs_v)\n",
    "\n",
    "        outputs_v = tf.layers.flatten(outputs_v)\n",
    "\n",
    "        outputs_v = tf.layers.dense(outputs_v,fc_units_v,activation=tf.nn.relu)\n",
    "\n",
    "        outputs_v = tf.layers.dense(outputs_v,1,activation=tf.nn.tanh)\n",
    "        \n",
    "        outputs_p = tf.layers.conv2d(inputs,filters=2,kernel_size=1,padding='same')\n",
    "        outputs_p = tf.layers.batch_normalization(outputs_p,training=training)\n",
    "        outputs_p = tf.nn.relu(outputs_p)\n",
    "        \n",
    "        outputs_p = tf.layers.flatten(outputs_p)\n",
    "        \n",
    "        outputs_p = tf.layers.dense(outputs_p,n_actions,activation=tf.nn.softmax)\n",
    "        return outputs_p, outputs_v\n",
    "\n",
    "    def inference(self,fc_units_v=32,num_res_module=4,training=True):\n",
    "        inputs = self.input_module(self.state_ph,filters,training) # 输入模块\n",
    "        \n",
    "        mid_values = inputs\n",
    "        for i_module in range(n_modules): # 残差模块\n",
    "            mid_values = self.residual_module(mid_values,filters,training)\n",
    "            \n",
    "        outputs_p, outputs_v = self.output_module(mid_values,fc_units_v,training)\n",
    "        return outputs_p, outputs_v\n",
    "        \n",
    "    def get_var_value(self,var,feed_dict):\n",
    "        return self.sess.run(var,feed_dict)\n",
    "    \n",
    "    def loss_op(self):\n",
    "        regularizer = tf.contrib.layers.l2_regularizer(scale=lambda_c)\n",
    "        l2_var = tf.contrib.layers.apply_regularization(\\\n",
    "                    regularizer,tf.trainable_variables())\n",
    "        \n",
    "        l_op = l2_var + \\\n",
    "            tf.reduce_mean(\\\n",
    "                tf.reduce_sum(\\\n",
    "                    tf.pow(self.z_ph - self.v_op,2)\\\n",
    "                              - tf.matmul(self.pi_ph,tf.transpose(tf.log(self.p_op))),reduction_indices=[1]))\n",
    "        return l_op\n",
    "    \n",
    "    def minimize(self,training=True):\n",
    "        if training:\n",
    "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "            with tf.control_dependencies(update_ops):\n",
    "                return tf.train.AdamOptimizer().minimize(self.l_op)\n",
    "        else:\n",
    "            return tf.train.AdamOptimizer().minimize(self.l_op)\n",
    "    \n",
    "    def update(self,feed_dict):\n",
    "        for it in range(n_iters):\n",
    "            self.sess.run(self.optimizer,feed_dict)\n",
    "        \n",
    "    def save_params(self):\n",
    "        self.saver.save(self.sess,save_path=model_path)\n",
    "        print(str(datetime.datetime.now())+\": latest model and params saved to path:\",model_path)\n",
    "        \n",
    "    def restore_params(self):\n",
    "        self.saver.restore(self.sess,save_path=model_path)\n",
    "        print(str(datetime.datetime.now())+\": last model and params restored from path\",model_path)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states = np.random.randn(5,3,3,1).astype(np.float32)\n",
    "zs = np.ones((5,1),np.float32)\n",
    "pis = np.tile(np.array([0.11]*9).astype(np.float32),(5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feed_dict = {net.state_ph:states,net.z_ph:zs,net.pi_ph:pis}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if os.path.exists(dir_path):\n",
    "    net.restore_params()\n",
    "    print(\"Yes\")\n",
    "    net.update(feed_dict)\n",
    "else:\n",
    "    net.update(feed_dict)\n",
    "\n",
    "print(\"Loss:\",net.get_var_value(net.l_op,feed_dict))\n",
    "net.save_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Loss:\",net.get_var_value(net.p_op,feed_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TreeNode 类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TreeNode:\n",
    "    def __init__(self,parent,prior_p,layer):\n",
    "        self._parent = parent\n",
    "        self._children = dict()\n",
    "        self._n_visits = 0 # 节点遍历次数\n",
    "        \n",
    "        self._Q = 0 # 动作平均值\n",
    "        self._W = 0 # 动作累计值\n",
    "        self._u = prior_p # 动作置信值, 根节点不存在置信值\n",
    "        self._p = prior_p # 动作先验概率\n",
    "        self.layer = layer\n",
    "        \n",
    "        \n",
    "    def render(self):\n",
    "        print(self.layer,\",Q:%.3f, W:%.3f, U:%.3f, N:%3d, Prob:%.3f\"%(self._Q,self._W,self._u,self._n_visits,self._p))\n",
    "        for action, node in self._children.items():\n",
    "            node.render()\n",
    "#             if node._children:\n",
    "#                 node.render()\n",
    "        \n",
    "        \n",
    "    def select(self):\n",
    "        return max(self._children.items(), key=lambda act_node: act_node[1].get_value())\n",
    "    \n",
    "    def get_value(self):\n",
    "        return self._Q + self._u\n",
    "    \n",
    "    def expand(self, action_priors):\n",
    "        for action, prob in action_priors:\n",
    "            if action not in self._children:\n",
    "                self._children[action] = TreeNode(self,prob,self.layer+1)\n",
    "                \n",
    "    def evaluation(self,leaf_value,c_puct):\n",
    "        self._n_visits += 1\n",
    "        self._W += leaf_value\n",
    "        self._Q = self._W / self._n_visits\n",
    "        if not self.is_root():\n",
    "            self._u = c_puct * self._p * np.sqrt(self._parent._n_visits) / (1+self._n_visits)\n",
    "\n",
    "    def is_root(self):\n",
    "        return self._parent is None\n",
    "    \n",
    "    def is_leaf(self):\n",
    "        return self._children == dict()\n",
    "    \n",
    "    def backup(self,leaf_value,c_puct):\n",
    "        \n",
    "        \n",
    "        if self._parent:\n",
    "            self._parent.backup(leaf_value,c_puct)\n",
    "            \n",
    "        self.evaluation(leaf_value,c_puct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree = TreeNode(None,1.0,1)\n",
    "tree.render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "action_priors = enumerate([0.1,0.2,.3,.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree.expand(action_priors)\n",
    "tree._children[0].expand(action_priors)\n",
    "tree.render()\n",
    "\n",
    "tree._children[2].get_value()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MCTS 类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MCTS:\n",
    "    def __init__(self,net,simulator):\n",
    "        self.net = net\n",
    "        self.simulator = simulator\n",
    "        \n",
    "        self._root = TreeNode(None,1.0,1)\n",
    "        self.root = self._root\n",
    "        self.c_puct = c_puct\n",
    "        self.max_search_depth = max_search_depth\n",
    "        self.n_search = n_search\n",
    "        self.cur_depth = 0\n",
    "        self.cur_node = self._root\n",
    "        \n",
    "        self.root_state = self.simulator.cur_state\n",
    "        self.cur_state = self.root_state.copy()\n",
    "        \n",
    "        self.pis = []\n",
    "        \n",
    "        \n",
    "    def search(self):\n",
    "        while self.cur_depth < self.max_search_depth:\n",
    "            if not self.cur_node.is_leaf():\n",
    "#                 print(self.cur_state)\n",
    "                \n",
    "                action, self.cur_node = self.cur_node.select()\n",
    "                \n",
    "                self.cur_state = self.simulator.get_state(self.cur_state.copy(),action)\n",
    "                \n",
    "                self.cur_depth += 1\n",
    "            else:\n",
    "                action_priors = enumerate(self.net.get_var_value(self.net.p_op,{self.net.state_ph:self.cur_state}).reshape(-1).tolist())\n",
    "                self.cur_node.expand(action_priors)\n",
    "                \n",
    "                leaf_value = self.net.get_var_value (self.net.v_op,{self.net.state_ph:self.cur_state})[0,0]\n",
    "#                 print(\"leaf_value\",leaf_value)\n",
    "                self.cur_node.backup(leaf_value,self.c_puct)\n",
    "    \n",
    "                \n",
    "    def policy(self,tau):\n",
    "        for it in range(self.n_search):\n",
    "#             print(\"第%d次搜索\"%(it+1))\n",
    "            self.search()\n",
    "            self.cur_node = self._root\n",
    "            self.cur_state = self.root_state\n",
    "            self.cur_depth = 0\n",
    "            \n",
    "        pi = [x._n_visits for _,x in self._root._children.items()]\n",
    "   \n",
    "        # 需考虑退火 温度系数，\n",
    "        pi = (np.power(pi,1/tau)/np.sum(np.power(pi,1/tau))).tolist()\n",
    "        self.pis.append(pi)\n",
    "        return pi\n",
    "    \n",
    "    def choice(self,tau):\n",
    "        pi = self.policy(tau)\n",
    "#         print(pi)\n",
    "        action = np.random.choice(range(len(pi)),p=pi)\n",
    "        self.action = action\n",
    "        self.next_prepare()\n",
    "        return action\n",
    "    \n",
    "    def next_prepare(self):\n",
    "        self._root = self._root._children[self.action]\n",
    "        self._root._parent = None\n",
    "        self.simulator.move(self.action)\n",
    "        self.root_state = self.simulator.cur_state.copy()\n",
    "        self.cur_state = self.root_state.copy()\n",
    "        \n",
    "        self.cur_depth = 0\n",
    "        self.cur_node = self._root\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulator 类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Simulator:\n",
    "    def __init__(self):\n",
    "        self.size = size\n",
    "        self.cur_state = np.zeros((1,size,size,1),dtype=np.float32)\n",
    "        self.records = [self.cur_state.copy()]\n",
    "        self.action_records = []\n",
    "        self.cur_hands = 0\n",
    "        self.n_actions = size**2\n",
    "        \n",
    "    def move(self,action):\n",
    "        self.cur_hands += 1\n",
    "        state = self.cur_state\n",
    "        \n",
    "        if action>self.n_actions or action<0:\n",
    "            print(\"pass\")\n",
    "        elif action == self.n_actions:\n",
    "            print(\"pass\")\n",
    "        else:\n",
    "            i = action//self.size\n",
    "            j = action % self.size\n",
    "            state[0,i,j,0] += 1\n",
    "        self.cur_state = state\n",
    "#         print(\"move\")\n",
    "        self.records.append(state.copy())\n",
    "        self.action_records.append(action)\n",
    "        \n",
    "    def get_state(self,state,action):\n",
    "        if  not (action>self.n_actions or action<0):\n",
    "            i = action//self.size\n",
    "            j = action % self.size\n",
    "            state[0,i,j,0] += 1\n",
    "            \n",
    "        return state\n",
    "    \n",
    "    def render(self):\n",
    "        print(\"hands:\",self.cur_hands)\n",
    "        print(\"state: \\n\")\n",
    "        print(self.cur_state.reshape((3,3)))\n",
    "        \n",
    "    def is_done(self):\n",
    "        if abs(np.linalg.det(state)) >= 1:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def who_win(self,state):\n",
    "        state = state.reshape((size,size))\n",
    "        res = np.linalg.det(state)\n",
    "        if res == 1.:\n",
    "            return 1.\n",
    "        elif res > 1.:\n",
    "            return -1.\n",
    "        else:\n",
    "            return 0.\n",
    "        \n",
    "    def state_rot(self):\n",
    "        pass\n",
    "    def board_to_state(self):\n",
    "        pass\n",
    "    def state_to_board(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simulator = Simulator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simulator.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simulator.move(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simulator.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mcts_tree = MCTS(net,simulator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mcts_tree._root.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_samples(simulator,mcts_tree,z):\n",
    "    feed_dict = dict()\n",
    "    temp = simulator.records\n",
    "    m = len(temp)\n",
    "    arr = np.zeros((m,size,size,1),np.float32)\n",
    "\n",
    "    for i in range(m):\n",
    "        arr[i,:,:,]=temp[i]\n",
    "        \n",
    "    feed_dict['states'] = arr\n",
    "    \n",
    "    feed_dict['zs'] = np.tile(np.array([z]).astype(np.float32),(m,1))\n",
    "    \n",
    "    temp = mcts_tree.pis\n",
    "    m = len(temp)\n",
    "    arr = np.zeros((m,n_actions),np.float32)\n",
    "    for i in range(m):\n",
    "        arr[i,:]=temp[i]\n",
    "        \n",
    "    feed_dict['pis'] = arr\n",
    "    \n",
    "    return feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lose, steps is 30\n"
     ]
    }
   ],
   "source": [
    "max_steps = 30\n",
    "\n",
    "samples = dict()\n",
    "for i in range(max_steps):\n",
    "#     simulator.render()\n",
    "    if simulator.who_win(simulator.cur_state) == 1.:\n",
    "        print(\"Win, steps is %d\"%(i+1))\n",
    "        \n",
    "        samples = get_samples(simulator,mcts_tree,1.)\n",
    "        break\n",
    "        \n",
    "    else:\n",
    "        action = mcts_tree.choice(1.)\n",
    "#         print(action)\n",
    "#         simulator.move(action)\n",
    "        if i == max_steps -1 :\n",
    "            samples = get_samples(simulator,mcts_tree,-1.)                        \n",
    "            print(\"Lose, steps is %d\"%(i+1))\n",
    "            \n",
    "# print(\"Records:\\n\",simulator.records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 9)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples['pis'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 3, 3, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples['states'][:-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feed_dict = {net.state_ph:samples['states'][:-1],net.z_ph:feed_dict['zs'],net.pi_ph:samples['pis']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.]]],\n",
       "\n",
       "\n",
       "       [[[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.]]],\n",
       "\n",
       "\n",
       "       [[[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.]]],\n",
       "\n",
       "\n",
       "       [[[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 0.],\n",
       "         [ 0.],\n",
       "         [ 1.]]],\n",
       "\n",
       "\n",
       "       [[[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 1.],\n",
       "         [ 0.],\n",
       "         [ 1.]]],\n",
       "\n",
       "\n",
       "       [[[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 1.],\n",
       "         [ 0.],\n",
       "         [ 2.]]],\n",
       "\n",
       "\n",
       "       [[[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 1.],\n",
       "         [ 0.],\n",
       "         [ 3.]]],\n",
       "\n",
       "\n",
       "       [[[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 2.],\n",
       "         [ 0.],\n",
       "         [ 3.]]],\n",
       "\n",
       "\n",
       "       [[[ 1.],\n",
       "         [ 1.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 2.],\n",
       "         [ 0.],\n",
       "         [ 3.]]],\n",
       "\n",
       "\n",
       "       [[[ 1.],\n",
       "         [ 1.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 2.],\n",
       "         [ 0.],\n",
       "         [ 4.]]],\n",
       "\n",
       "\n",
       "       [[[ 1.],\n",
       "         [ 2.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 2.],\n",
       "         [ 0.],\n",
       "         [ 4.]]],\n",
       "\n",
       "\n",
       "       [[[ 1.],\n",
       "         [ 2.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 2.],\n",
       "         [ 0.],\n",
       "         [ 5.]]],\n",
       "\n",
       "\n",
       "       [[[ 1.],\n",
       "         [ 2.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 2.],\n",
       "         [ 0.],\n",
       "         [ 6.]]],\n",
       "\n",
       "\n",
       "       [[[ 1.],\n",
       "         [ 2.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 2.],\n",
       "         [ 0.],\n",
       "         [ 7.]]],\n",
       "\n",
       "\n",
       "       [[[ 1.],\n",
       "         [ 2.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 2.],\n",
       "         [ 0.],\n",
       "         [ 8.]]],\n",
       "\n",
       "\n",
       "       [[[ 1.],\n",
       "         [ 2.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 2.],\n",
       "         [ 0.],\n",
       "         [ 9.]]],\n",
       "\n",
       "\n",
       "       [[[ 1.],\n",
       "         [ 2.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 2.],\n",
       "         [ 0.],\n",
       "         [10.]]],\n",
       "\n",
       "\n",
       "       [[[ 1.],\n",
       "         [ 2.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 2.],\n",
       "         [ 0.],\n",
       "         [11.]]],\n",
       "\n",
       "\n",
       "       [[[ 1.],\n",
       "         [ 2.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 2.],\n",
       "         [ 0.],\n",
       "         [12.]]],\n",
       "\n",
       "\n",
       "       [[[ 1.],\n",
       "         [ 3.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 2.],\n",
       "         [ 0.],\n",
       "         [12.]]],\n",
       "\n",
       "\n",
       "       [[[ 1.],\n",
       "         [ 3.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 2.],\n",
       "         [ 0.],\n",
       "         [13.]]],\n",
       "\n",
       "\n",
       "       [[[ 1.],\n",
       "         [ 3.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 2.],\n",
       "         [ 0.],\n",
       "         [14.]]],\n",
       "\n",
       "\n",
       "       [[[ 1.],\n",
       "         [ 4.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 2.],\n",
       "         [ 0.],\n",
       "         [14.]]],\n",
       "\n",
       "\n",
       "       [[[ 1.],\n",
       "         [ 4.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 2.],\n",
       "         [ 0.],\n",
       "         [15.]]],\n",
       "\n",
       "\n",
       "       [[[ 1.],\n",
       "         [ 4.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 2.],\n",
       "         [ 0.],\n",
       "         [16.]]],\n",
       "\n",
       "\n",
       "       [[[ 1.],\n",
       "         [ 4.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 2.],\n",
       "         [ 0.],\n",
       "         [17.]]],\n",
       "\n",
       "\n",
       "       [[[ 1.],\n",
       "         [ 5.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 2.],\n",
       "         [ 0.],\n",
       "         [17.]]],\n",
       "\n",
       "\n",
       "       [[[ 1.],\n",
       "         [ 5.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 2.],\n",
       "         [ 0.],\n",
       "         [18.]]],\n",
       "\n",
       "\n",
       "       [[[ 1.],\n",
       "         [ 5.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 2.],\n",
       "         [ 0.],\n",
       "         [19.]]],\n",
       "\n",
       "\n",
       "       [[[ 1.],\n",
       "         [ 5.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 2.],\n",
       "         [ 0.],\n",
       "         [20.]]],\n",
       "\n",
       "\n",
       "       [[[ 1.],\n",
       "         [ 6.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 2.],\n",
       "         [ 0.],\n",
       "         [20.]]]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples['states']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mcts_tree.root.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simulator.cur_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def play(self):\n",
    "        pass\n",
    "    def train(self):\n",
    "        pass\n",
    "    def update_net(self):\n",
    "        pass\n",
    "    def save_samples(self):\n",
    "        pass\n",
    "    def display(self):\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

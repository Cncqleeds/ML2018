{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Net:\n",
    "    def __init__(self,data,model_path=\"./Model_save/model_mtcs.ckpt\"):\n",
    "        self.s = tf.constant(data,dtype=tf.float32)\n",
    "        self.model_path = model_path\n",
    "        self.shape = data.shape\n",
    "        self.p, self.v = self.inference(self.s)\n",
    "        \n",
    "    def reset(self,data):\n",
    "        self.s = tf.constant(data,dtype=tf.float32)\n",
    "        self.shape = data.shape\n",
    "#         self.p, self.v = self.inference(self.s)\n",
    "        \n",
    "    def input_module(self,inputs,filters=256):\n",
    "        outputs = tf.reshape(inputs,[1,self.shape[0],self.shape[1],-1]) # 后续改进\n",
    "        outputs = tf.layers.conv2d(outputs,filters=filters,kernel_size=3,padding='same')\n",
    "        outputs = tf.layers.batch_normalization(outputs)\n",
    "        outputs = tf.nn.relu(outputs)\n",
    "        return outputs\n",
    "    \n",
    "    def residual_module(self,inputs,filters=256):\n",
    "        outputs = tf.layers.conv2d(inputs,filters=filters,kernel_size=3,padding='same')\n",
    "        outputs = tf.layers.batch_normalization(outputs)\n",
    "        outputs = tf.nn.relu(outputs)\n",
    "\n",
    "        outputs = tf.layers.conv2d(outputs,filters=filters,kernel_size=3,padding='same')\n",
    "        outputs = tf.layers.batch_normalization(outputs)\n",
    "\n",
    "        outputs += inputs\n",
    "        outputs = tf.nn.relu(outputs)  \n",
    "        return outputs\n",
    "    \n",
    "    def output_module(self,inputs,fc_units_v=256,fc_units_p=19*19+1):\n",
    "        outputs_v = tf.layers.conv2d(inputs,filters=1,kernel_size=1,padding='same')\n",
    "        outputs_v = tf.layers.batch_normalization(outputs_v)\n",
    "        outputs_v = tf.nn.relu(outputs_v)\n",
    "\n",
    "        outputs_v = tf.layers.flatten(outputs_v)\n",
    "\n",
    "        outputs_v = tf.layers.dense(outputs_v,fc_units_v,activation=tf.nn.relu)\n",
    "\n",
    "        outputs_v = tf.layers.dense(outputs_v,1,activation=tf.nn.tanh)\n",
    "        \n",
    "        outputs_p = tf.layers.conv2d(inputs,filters=2,kernel_size=1,padding='same')\n",
    "        outputs_p = tf.layers.batch_normalization(outputs_p)\n",
    "        outputs_p = tf.nn.relu(outputs_p)\n",
    "        \n",
    "        outputs_p = tf.layers.flatten(outputs_p)\n",
    "        \n",
    "        outputs_p = tf.layers.dense(outputs_p,fc_units_p,activation=tf.nn.softmax)\n",
    "        return outputs_p, outputs_v\n",
    "    \n",
    "    def inference(self,inputs,filters=4,fc_units_v=32,fc_units_p=4,num_res_module=4):\n",
    "        inputs = self.input_module(inputs,filters)\n",
    "        \n",
    "        mid_values = inputs\n",
    "        \n",
    "        for i_module in range(num_res_module):\n",
    "            mid_values = self.residual_module(mid_values,filters)\n",
    "            \n",
    "        outputs_p, outputs_v = self.output_module(mid_values,fc_units_v,fc_units_p)\n",
    "        \n",
    "        self.train_vars = tf.trainable_variables()\n",
    "        self.saver = tf.train.Saver(self.train_vars)\n",
    "\n",
    "        return outputs_p, outputs_v\n",
    "    \n",
    "    def pre_train(self,v_list,p_list,z,mcts_list,c=0.0001):\n",
    "        loss = tf.Variable(0.,trainable=False,dtype=tf.float32)\n",
    "        for v in v_list:\n",
    "            loss = tf.add(loss,tf.square(v-z)) \n",
    "\n",
    "        for p,m in zip(p_list,mcts_list):\n",
    "            loss = tf.add(loss,-tf.matmul(tf.log(p),m)) \n",
    "\n",
    "        var = tf.trainable_variables()\n",
    "#         print(len(var))\n",
    "        regularizer = tf.contrib.layers.l2_regularizer(scale=c)\n",
    "        l2_var = tf.contrib.layers.apply_regularization(regularizer,var)\n",
    "        \n",
    "        loss = tf.add(loss, l2_var)\n",
    "\n",
    "        self.loss = loss\n",
    "        self.optimizer = tf.train.AdamOptimizer().minimize(self.loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = Net(np.zeros((2,2),dtype=np.float32))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.reset(2*np.random.randn(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v_list = [net.v,net.v,net.v,net.v]\n",
    "p_list = [net.p,net.p,net.p]\n",
    "z = tf.constant(1.0,dtype=tf.float32) \n",
    "const_p = tf.constant([0.2,0.1,0.6,0.1],dtype=tf.float32)\n",
    "const_p = tf.reshape(const_p,shape=[-1,1])\n",
    "mcts_list = [const_p,const_p,const_p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "net.pre_train(v_list,p_list,z,mcts_list,c=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    try:\n",
    "        net.saver.restore(sess,save_path=net.model_path)\n",
    "        print(\"last model and params restore path\",net.model_path)\n",
    "    except Exception as e:\n",
    "        print(e.message)\n",
    "        print(\"not found restore path!\")\n",
    "    finally:\n",
    "        for it in range(2):\n",
    "            sess.run(net.optimizer)\n",
    "            \n",
    "        net.saver.save(sess,save_path=net.model_path)\n",
    "        print(\"latest model and prams save path:\",net.model_path)\n",
    "        \n",
    "        print(sess.run(net.loss))\n",
    "        print(sess.run(net.p))\n",
    "        print(sess.run(net.v))\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MCTS:\n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "        self.net = Net(self.data,params)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

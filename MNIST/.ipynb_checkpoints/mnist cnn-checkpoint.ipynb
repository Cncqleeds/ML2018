{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting E:\\home\\workspace\\datasets\\mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting E:\\home\\workspace\\datasets\\mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting E:\\home\\workspace\\datasets\\mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting E:\\home\\workspace\\datasets\\mnist\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "train_dir = \"E:\\\\home\\\\workspace\\\\datasets\\\\mnist\"\n",
    "mnist = input_data.read_data_sets(train_dir=train_dir,one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(inputs):\n",
    "    outputs = tf.reshape(inputs,[-1,28,28,1])\n",
    "    outputs = tf.layers.conv2d(outputs,filters=6,kernel_size=3)\n",
    "    outputs = tf.layers.batch_normalization(outputs)\n",
    "    outputs = tf.nn.relu(outputs)\n",
    "    \n",
    "    outputs = tf.layers.conv2d(outputs,filters=16,kernel_size=3)\n",
    "    outputs = tf.layers.batch_normalization(outputs)\n",
    "    outputs = tf.nn.relu(outputs)\n",
    "    \n",
    "    outputs = tf.layers.conv2d(outputs,filters=64,kernel_size=3)\n",
    "    outputs = tf.layers.batch_normalization(outputs)\n",
    "    outputs = tf.nn.relu(outputs)\n",
    "    \n",
    "    outputs = tf.layers.flatten(outputs)\n",
    "    \n",
    "    outputs = tf.layers.dense(outputs,84,activation=tf.nn.relu)\n",
    "    \n",
    "    outputs = tf.layers.dense(outputs,10,activation=tf.nn.softmax)\n",
    "    \n",
    "    return outputs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_2/Softmax:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32,shape=[None,784])\n",
    "y = tf.placeholder(tf.float32,(None,10))\n",
    "\n",
    "y_pred = inference(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var = tf.trainable_variables()\n",
    "regularizer = tf.contrib.layers.l2_regularizer(scale=.0001)\n",
    "l2_var = tf.contrib.layers.apply_regularization(regularizer,var)\n",
    "\n",
    "loss = tf.reduce_mean(tf.reduce_sum(-y*tf.log(y_pred),reduction_indices=[1])) + l2_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(y_pred,axis=1),tf.argmax(y,axis=1)),tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = \"./Model_save/model_cnn.ckpt\"\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Iter num: 1, Test loss is 2.20, accuracy is 0.289\n",
      "> Iter num: 21, Test loss is 0.50, accuracy is 0.861\n",
      "> Iter num: 41, Test loss is 0.33, accuracy is 0.916\n",
      "> Iter num: 61, Test loss is 0.23, accuracy is 0.942\n",
      "> Iter num: 81, Test loss is 0.17, accuracy is 0.959\n",
      "> Iter num: 101, Test loss is 0.12, accuracy is 0.976\n",
      "> Iter num: 121, Test loss is 0.13, accuracy is 0.972\n",
      "> Iter num: 141, Test loss is 0.13, accuracy is 0.967\n",
      "> Iter num: 161, Test loss is 0.10, accuracy is 0.980\n",
      "> Iter num: 181, Test loss is 0.12, accuracy is 0.970\n",
      "> Iter num: 201, Test loss is 0.11, accuracy is 0.964\n",
      "> Iter num: 221, Test loss is 0.10, accuracy is 0.972\n",
      "> Iter num: 241, Test loss is 0.15, accuracy is 0.956\n",
      "> Iter num: 261, Test loss is 0.09, accuracy is 0.982\n",
      "> Iter num: 281, Test loss is 0.11, accuracy is 0.976\n",
      "> Iter num: 301, Test loss is 0.09, accuracy is 0.978\n",
      "> Iter num: 321, Test loss is 0.09, accuracy is 0.981\n",
      "> Iter num: 341, Test loss is 0.11, accuracy is 0.975\n",
      "> Iter num: 361, Test loss is 0.09, accuracy is 0.984\n",
      "> Iter num: 381, Test loss is 0.08, accuracy is 0.986\n",
      "> Iter num: 401, Test loss is 0.10, accuracy is 0.973\n",
      "> Iter num: 421, Test loss is 0.10, accuracy is 0.980\n",
      "> Iter num: 441, Test loss is 0.07, accuracy is 0.986\n",
      "> Iter num: 461, Test loss is 0.09, accuracy is 0.980\n",
      "> Iter num: 481, Test loss is 0.08, accuracy is 0.984\n",
      "> Iter num: 501, Test loss is 0.08, accuracy is 0.983\n",
      "> Iter num: 521, Test loss is 0.08, accuracy is 0.983\n",
      "> Iter num: 541, Test loss is 0.09, accuracy is 0.985\n",
      "> Iter num: 561, Test loss is 0.09, accuracy is 0.976\n",
      "> Iter num: 581, Test loss is 0.08, accuracy is 0.982\n",
      "> Iter num: 601, Test loss is 0.10, accuracy is 0.979\n",
      "> Iter num: 621, Test loss is 0.08, accuracy is 0.985\n",
      "> Iter num: 641, Test loss is 0.08, accuracy is 0.984\n",
      "> Iter num: 661, Test loss is 0.08, accuracy is 0.986\n",
      "> Iter num: 681, Test loss is 0.09, accuracy is 0.984\n",
      "> Iter num: 701, Test loss is 0.07, accuracy is 0.987\n",
      "> Iter num: 721, Test loss is 0.08, accuracy is 0.986\n",
      "> Iter num: 741, Test loss is 0.08, accuracy is 0.983\n",
      "> Iter num: 761, Test loss is 0.06, accuracy is 0.990\n",
      "> Iter num: 781, Test loss is 0.07, accuracy is 0.985\n",
      "> Iter num: 801, Test loss is 0.10, accuracy is 0.981\n",
      "> Iter num: 821, Test loss is 0.08, accuracy is 0.985\n",
      "> Iter num: 841, Test loss is 0.06, accuracy is 0.992\n",
      "> Iter num: 861, Test loss is 0.08, accuracy is 0.988\n",
      "> Iter num: 881, Test loss is 0.07, accuracy is 0.989\n",
      "> Iter num: 901, Test loss is 0.07, accuracy is 0.988\n",
      "> Iter num: 921, Test loss is 0.08, accuracy is 0.982\n",
      "> Iter num: 941, Test loss is 0.11, accuracy is 0.977\n",
      "> Iter num: 961, Test loss is 0.07, accuracy is 0.987\n",
      "> Iter num: 981, Test loss is 0.10, accuracy is 0.974\n",
      "> Iter num: 1001, Test loss is 0.08, accuracy is 0.991\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    try:\n",
    "        saver.restore(sess,save_path=model_path)\n",
    "        print(\"last model and prams restore path:\",model_path)\n",
    "     \n",
    "    except:\n",
    "        print(\"not found restore path\")\n",
    "        \n",
    "    finally:\n",
    "        for it in range(101):\n",
    "            xs,ys = mnist.train.next_batch(128)\n",
    "            sess.run(optimizer,feed_dict={x:xs,y:ys})\n",
    "\n",
    "            if it % 10 == 0:\n",
    "                xs,ys = mnist.test.next_batch(3000)\n",
    "                v_loss, v_accuracy = sess.run([loss,accuracy],{x:xs,y:ys})\n",
    "                print(\"> Iter num: %d, Test loss is %.2f, accuracy is %.4f\"%(it+1,v_loss,v_accuracy))\n",
    "\n",
    "        saver.save(sess=sess,save_path=model_path)\n",
    "        print(\"latest model and prams save path:\",model_path)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting E:\\home\\workspace\\datasets\\mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting E:\\home\\workspace\\datasets\\mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting E:\\home\\workspace\\datasets\\mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting E:\\home\\workspace\\datasets\\mnist\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "train_dir = \"E:\\\\home\\\\workspace\\\\datasets\\\\mnist\"\n",
    "mnist = input_data.read_data_sets(train_dir=train_dir,one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,shape=[None,784])\n",
    "y = tf.placeholder(tf.float32,(None,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_module(inputs,filters=64):\n",
    "    outputs = tf.reshape(inputs,[-1,28,28,1])\n",
    "    outputs = tf.layers.conv2d(outputs,filters=filters,kernel_size=3,padding='same')\n",
    "    outputs = tf.layers.batch_normalization(outputs)\n",
    "    outputs = tf.nn.relu(outputs)\n",
    "    \n",
    "    return outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def residual_module(inputs,filters=64):\n",
    "    outputs = tf.layers.conv2d(inputs,filters=filters,kernel_size=3,padding='same')\n",
    "    outputs = tf.layers.batch_normalization(outputs)\n",
    "    outputs = tf.nn.relu(outputs)\n",
    "    \n",
    "    outputs = tf.layers.conv2d(outputs,filters=filters,kernel_size=3,padding='same')\n",
    "    outputs = tf.layers.batch_normalization(outputs)\n",
    "    \n",
    "    outputs += inputs\n",
    "    outputs = tf.nn.relu(outputs)  \n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output_module(inputs,fc_units=256):\n",
    "    outputs = tf.layers.conv2d(inputs,filters=1,kernel_size=1,padding='same')\n",
    "    outputs = tf.layers.batch_normalization(outputs)\n",
    "    outputs = tf.nn.relu(outputs)\n",
    "    \n",
    "    outputs = tf.layers.flatten(outputs)\n",
    "    \n",
    "    outputs = tf.layers.dense(outputs,fc_units,activation=tf.nn.relu)\n",
    "    \n",
    "    outputs = tf.layers.dense(outputs,10,activation=tf.nn.softmax)\n",
    "    \n",
    "    return outputs\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(inputs,filters=16,fc_units=128,num_res_module=4):\n",
    "    inputs = input_module(inputs,filters)\n",
    "    \n",
    "    mid_values = inputs\n",
    "    for i_module in range(num_res_module):\n",
    "        mid_values = residual_module(mid_values,filters)\n",
    "        \n",
    "    outputs = output_module(mid_values,fc_units)\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_2/Softmax:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = inference(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var = tf.trainable_variables()\n",
    "regularizer = tf.contrib.layers.l2_regularizer(scale=.0001)\n",
    "l2_var = tf.contrib.layers.apply_regularization(regularizer,var)\n",
    "\n",
    "loss = tf.reduce_mean(tf.reduce_sum(-y*tf.log(y_pred),reduction_indices=[1])) + l2_var\n",
    "\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(y_pred,axis=1),tf.argmax(y,axis=1)),tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = \"./Model_save/model_resnet.ckpt\"\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Iter num: 1, Test loss is 2.26, accuracy is 0.20\n",
      "> Iter num: 3, Test loss is 2.17, accuracy is 0.29\n",
      "> Iter num: 5, Test loss is 1.93, accuracy is 0.41\n",
      "> Iter num: 7, Test loss is 1.55, accuracy is 0.59\n",
      "> Iter num: 9, Test loss is 1.10, accuracy is 0.69\n",
      "> Iter num: 11, Test loss is 0.92, accuracy is 0.70\n",
      "> Iter num: 13, Test loss is 0.95, accuracy is 0.73\n",
      "> Iter num: 15, Test loss is 0.71, accuracy is 0.78\n",
      "> Iter num: 17, Test loss is 0.72, accuracy is 0.76\n",
      "> Iter num: 19, Test loss is 0.60, accuracy is 0.82\n",
      "> Iter num: 21, Test loss is 0.64, accuracy is 0.81\n",
      "> Iter num: 23, Test loss is 0.61, accuracy is 0.83\n",
      "> Iter num: 25, Test loss is 0.50, accuracy is 0.87\n",
      "> Iter num: 27, Test loss is 0.56, accuracy is 0.84\n",
      "> Iter num: 29, Test loss is 0.48, accuracy is 0.87\n",
      "> Iter num: 31, Test loss is 0.46, accuracy is 0.87\n",
      "> Iter num: 33, Test loss is 0.41, accuracy is 0.88\n",
      "> Iter num: 35, Test loss is 0.38, accuracy is 0.90\n",
      "> Iter num: 37, Test loss is 0.44, accuracy is 0.88\n",
      "> Iter num: 39, Test loss is 0.37, accuracy is 0.89\n",
      "> Iter num: 41, Test loss is 0.32, accuracy is 0.90\n",
      "> Iter num: 43, Test loss is 0.37, accuracy is 0.89\n",
      "> Iter num: 45, Test loss is 0.34, accuracy is 0.90\n",
      "> Iter num: 47, Test loss is 0.40, accuracy is 0.89\n",
      "> Iter num: 49, Test loss is 0.31, accuracy is 0.91\n",
      "> Iter num: 51, Test loss is 0.29, accuracy is 0.90\n",
      "> Iter num: 53, Test loss is 0.28, accuracy is 0.91\n",
      "> Iter num: 55, Test loss is 0.34, accuracy is 0.91\n",
      "> Iter num: 57, Test loss is 0.33, accuracy is 0.91\n",
      "> Iter num: 59, Test loss is 0.35, accuracy is 0.89\n",
      "> Iter num: 61, Test loss is 0.31, accuracy is 0.91\n",
      "> Iter num: 63, Test loss is 0.28, accuracy is 0.91\n",
      "> Iter num: 65, Test loss is 0.34, accuracy is 0.90\n",
      "> Iter num: 67, Test loss is 0.34, accuracy is 0.90\n",
      "> Iter num: 69, Test loss is 0.24, accuracy is 0.93\n",
      "> Iter num: 71, Test loss is 0.26, accuracy is 0.92\n",
      "> Iter num: 73, Test loss is 0.26, accuracy is 0.91\n",
      "> Iter num: 75, Test loss is 0.23, accuracy is 0.93\n",
      "> Iter num: 77, Test loss is 0.32, accuracy is 0.92\n",
      "> Iter num: 79, Test loss is 0.25, accuracy is 0.93\n",
      "> Iter num: 81, Test loss is 0.27, accuracy is 0.92\n",
      "> Iter num: 83, Test loss is 0.29, accuracy is 0.90\n",
      "> Iter num: 85, Test loss is 0.26, accuracy is 0.91\n",
      "> Iter num: 87, Test loss is 0.23, accuracy is 0.93\n",
      "> Iter num: 89, Test loss is 0.22, accuracy is 0.94\n",
      "> Iter num: 91, Test loss is 0.23, accuracy is 0.91\n",
      "> Iter num: 93, Test loss is 0.27, accuracy is 0.92\n",
      "> Iter num: 95, Test loss is 0.28, accuracy is 0.92\n",
      "> Iter num: 97, Test loss is 0.23, accuracy is 0.94\n",
      "> Iter num: 99, Test loss is 0.23, accuracy is 0.92\n",
      "> Iter num: 101, Test loss is 0.21, accuracy is 0.93\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    try:\n",
    "        saver.restore(sess,save_path=model_path)\n",
    "        print(\"last model and prams restore path:\",model_path)\n",
    "     \n",
    "    except:\n",
    "        print(\"not found restore path\")\n",
    "        \n",
    "    finally:\n",
    "        for it in range(101):\n",
    "            xs,ys = mnist.train.next_batch(128)\n",
    "            sess.run(optimizer,feed_dict={x:xs,y:ys})\n",
    "\n",
    "            if it % 10 == 0:\n",
    "                xs,ys = mnist.test.next_batch(3000)\n",
    "                v_loss, v_accuracy = sess.run([loss,accuracy],{x:xs,y:ys})\n",
    "                print(\"> Iter num: %d, Test loss is %.2f, accuracy is %.4f\"%(it+1,v_loss,v_accuracy))\n",
    "\n",
    "        saver.save(sess=sess,save_path=model_path)\n",
    "        print(\"latest model and prams save path:\",model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

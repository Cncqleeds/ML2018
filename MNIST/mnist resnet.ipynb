{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "WARNING:tensorflow:From <ipython-input-1-cd436e34ffa0>:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting E:\\home\\workspace\\datasets\\mnist\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting E:\\home\\workspace\\datasets\\mnist\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting E:\\home\\workspace\\datasets\\mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting E:\\home\\workspace\\datasets\\mnist\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "\n",
    "train_dir = \"E:\\\\home\\\\workspace\\\\datasets\\\\mnist\"\n",
    "mnist = input_data.read_data_sets(train_dir=train_dir,one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dimension(None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32,shape=[None,784])\n",
    "y = tf.placeholder(tf.float32,(None,10))\n",
    "\n",
    "x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_module(inputs,filters=64):\n",
    "    outputs = tf.reshape(inputs,[-1,28,28,1])\n",
    "    outputs = tf.layers.conv2d(outputs,filters=filters,kernel_size=3,padding='same')\n",
    "    outputs = tf.layers.batch_normalization(outputs)\n",
    "    outputs = tf.nn.relu(outputs)\n",
    "    \n",
    "    return outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def residual_module(inputs,filters=64):\n",
    "    outputs = tf.layers.conv2d(inputs,filters=filters,kernel_size=3,padding='same')\n",
    "    outputs = tf.layers.batch_normalization(outputs)\n",
    "    outputs = tf.nn.relu(outputs)\n",
    "    \n",
    "    outputs = tf.layers.conv2d(outputs,filters=filters,kernel_size=3,padding='same')\n",
    "    outputs = tf.layers.batch_normalization(outputs)\n",
    "    \n",
    "    outputs += inputs\n",
    "    outputs = tf.nn.relu(outputs)  \n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output_module(inputs,fc_units=256):\n",
    "    outputs = tf.layers.conv2d(inputs,filters=1,kernel_size=1,padding='same')\n",
    "    outputs = tf.layers.batch_normalization(outputs)\n",
    "    outputs = tf.nn.relu(outputs)\n",
    "    \n",
    "    outputs = tf.layers.flatten(outputs)\n",
    "    \n",
    "    outputs = tf.layers.dense(outputs,fc_units,activation=tf.nn.relu)\n",
    "    \n",
    "    outputs = tf.layers.dense(outputs,10,activation=tf.nn.softmax)\n",
    "    \n",
    "    return outputs\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(inputs,filters=16,fc_units=128,num_res_module=4):\n",
    "    inputs = input_module(inputs,filters)\n",
    "    \n",
    "    mid_values = inputs\n",
    "    for i_module in range(num_res_module):\n",
    "        mid_values = residual_module(mid_values,filters)\n",
    "        \n",
    "    outputs = output_module(mid_values,fc_units)\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = inference(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var = tf.trainable_variables()\n",
    "regularizer = tf.contrib.layers.l2_regularizer(scale=.0001)\n",
    "l2_var = tf.contrib.layers.apply_regularization(regularizer,var)\n",
    "\n",
    "loss = tf.reduce_mean(tf.reduce_sum(-y*tf.log(y_pred),reduction_indices=[1])) + l2_var\n",
    "\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(y_pred,axis=1),tf.argmax(y,axis=1)),tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = \"./Model_save/model_resnet.ckpt\"\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    try:\n",
    "        saver.restore(sess,save_path=model_path)\n",
    "        print(\"last model and params restore path:\",model_path)\n",
    "     \n",
    "    except:\n",
    "        print(\"not found restore path\")\n",
    "        \n",
    "    finally:\n",
    "        for it in range(1001):\n",
    "            xs,ys = mnist.train.next_batch(128)\n",
    "            sess.run(optimizer,feed_dict={x:xs,y:ys})\n",
    "\n",
    "            if it % 100 == 0:\n",
    "                test_xs,test_ys = mnist.test.next_batch(1000)\n",
    "                train_xs, train_ys = mnist.train.next_batch(1000)\n",
    "                \n",
    "                v_loss, v_accuracy = sess.run([loss,accuracy],{x:test_xs,y:test_ys})\n",
    "                print(\"> Iter num: %d, Test loss is %.2f, accuracy is %.4f\"%(it+1,v_loss,v_accuracy))\n",
    "                \n",
    "                v_loss, v_accuracy = sess.run([loss,accuracy],{x:train_xs,y:train_ys})\n",
    "                print(\"> Iter num: %d, Trian loss is %.2f, accuracy is %.4f\"%(it+1,v_loss,v_accuracy))\n",
    "\n",
    "        saver.save(sess=sess,save_path=model_path)\n",
    "        print(\"latest model and params save path:\",model_path)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "train_dir = \"E:\\\\home\\\\workspace\\\\datasets\\\\mnist\"\n",
    "mnist = input_data.read_data_sets(train_dir=train_dir,one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(inputs,training=True):\n",
    "    outputs = tf.reshape(inputs,[-1,28,28,1])\n",
    "    outputs = tf.layers.conv2d(outputs,filters=6,kernel_size=3)\n",
    "    outputs = tf.layers.batch_normalization(outputs,training=training)\n",
    "    outputs = tf.nn.relu(outputs)\n",
    "    \n",
    "    outputs = tf.layers.conv2d(outputs,filters=16,kernel_size=3)\n",
    "    outputs = tf.layers.batch_normalization(outputs,training=training)\n",
    "    outputs = tf.nn.relu(outputs)\n",
    "    \n",
    "    outputs = tf.layers.conv2d(outputs,filters=64,kernel_size=3)\n",
    "    outputs = tf.layers.batch_normalization(outputs,training=training)\n",
    "    outputs = tf.nn.relu(outputs)\n",
    "    \n",
    "    outputs = tf.layers.flatten(outputs)\n",
    "    \n",
    "    outputs = tf.layers.dense(outputs,84,activation=tf.nn.relu)\n",
    "    \n",
    "    outputs = tf.layers.dense(outputs,10,activation=tf.nn.softmax)\n",
    "    \n",
    "    return outputs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,shape=[None,784])\n",
    "y = tf.placeholder(tf.float32,(None,10))\n",
    "\n",
    "y_pred = inference(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var = tf.trainable_variables()\n",
    "regularizer = tf.contrib.layers.l2_regularizer(scale=.0001)\n",
    "l2_var = tf.contrib.layers.apply_regularization(regularizer,var)\n",
    "\n",
    "loss = tf.reduce_mean(tf.reduce_sum(-y*tf.log(y_pred),reduction_indices=[1])) + l2_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training = False\n",
    "if training:\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "else:\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(y_pred,axis=1),tf.argmax(y,axis=1)),tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var_list = tf.trainable_variables()\n",
    "print(len(var_list))\n",
    "g_list = tf.global_variables()\n",
    "bn_moving_vars = [g for g in g_list if 'moving_mean' in g.name]\n",
    "bn_moving_vars += [g for g in g_list if 'moving_variance' in g.name]\n",
    "var_list += bn_moving_vars\n",
    "print(len(var_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = \"./Model_save/model_cnn.ckpt\"\n",
    "saver = tf.train.Saver(var_list=var_list, max_to_keep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    try:\n",
    "        saver.restore(sess,save_path=model_path)\n",
    "        print(\"last model and prams restore path:\",model_path)\n",
    "     \n",
    "    except Exception as e:\n",
    "        print(e.message())\n",
    "        print(\"not found restore path\")\n",
    "        \n",
    "    finally:\n",
    "        for it in range(11):\n",
    "            xs,ys = mnist.train.next_batch(128)\n",
    "            sess.run(optimizer,feed_dict={x:xs,y:ys})\n",
    "\n",
    "            if it % 10 == 0:\n",
    "                xs,ys = mnist.test.next_batch(3000)\n",
    "                v_loss, v_accuracy = sess.run([loss,accuracy],{x:xs,y:ys})\n",
    "                print(\"> Iter num: %d, Test loss is %.2f, accuracy is %.4f\"%(it+1,v_loss,v_accuracy))\n",
    "\n",
    "        saver.save(sess=sess,save_path=model_path)\n",
    "        print(\"latest model and prams save path:\",model_path)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
